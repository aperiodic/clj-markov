Accuracy error rate Association learning Attribute field, variable, feature Categorical Continuous quantitative Classifier Confusion matrix Negative Positive Accuracy True positive rate Recall, Sensitivity True negative rate Specificity Precision False positive rate False negative rate Coverage Cost utility/loss/payoff Cross-validation Data cleaning/cleansing Data mining Data set Dimension Error rate Example Feature Feature vector record, tuple Field i.i.d. sample Inducer / induction algorithm Instance example, case, record Knowledge discovery Loss Machine learning Missing value Model Model deployment OLAP MOLAP, ROLAP Record Regressor Resubstitution accuracy error/loss Schema Sensitivity Specificity Supervised learning Tuple Unsupervised learning Utility A/B testing accuracy activation function AdaGrad AUC Area under the ROC Curve backpropagation baseline batch batch size bias binary classification binning bucketing calibration layer candidate sampling categorical data checkpoint class class-imbalanced data set classification model classification threshold collaborative filtering confusion matrix continuous feature convergence convex function convex optimization convex set cost cross-entropy custom Estimator data set Dataset API tf.data decision boundary dense layer deep model dense feature derived feature discrete feature dropout regularization dynamic model early stopping embeddings empirical risk minimization ERM ensemble epoch Estimator example false negative FN false positive FP false positive rate FP rate feature feature columns FeatureColumns feature cross feature engineering feature set feature spec full softmax fully connected layer generalization generalized linear model gradient gradient clipping gradient descent graph heuristic hidden layer hinge loss holdout data hyperparameter hyperplane independently and identically distributed i.i.d inference input function input layer instance interpretability inter-rater agreement iteration Keras Kernel Support Vector Machines KSVMs L1 loss L1 regularization L2 loss L2 regularization label labeled example lambda layer Layers API tf.layers learning rate least squares regression linear regression logistic regression Log Loss loss machine learning Mean Squared Error MSE metric Metrics API tf.metrics mini-batch mini-batch stochastic gradient descent SGD ML model model training Momentum multi-class classification multinomial classification NaN trap negative class neural network neuron node normalization numerical data numpy objective offline inference one-hot encoding one-vs.-all online inference Operation op optimizer outliers output layer overfitting pandas parameter Parameter Server PS parameter update partial derivative partitioning strategy performance perplexity pipeline positive class precision prediction prediction bias pre-made Estimator pre-trained model prior belief queue rank rater recall Rectified Linear Unit ReLU regression model regularization regularization rate representation ROC receiver operating characteristic Curve root directory Root Mean Squared Error RMSE SavedModel Saver scaling scikit-learn semi-supervised learning sequence model session sigmoid function softmax sparse feature squared hinge loss squared loss static model stationarity step step size stochastic gradient descent SGD structural risk minimization SRM summary supervised machine learning synthetic feature target temporal data Tensor Tensor Processing Unit TPU Tensor rank Tensor shape Tensor size TensorBoard TensorFlow TensorFlow Playground TensorFlow Serving test set tf.Example time series analysis training training set transfer learning true negative TN true positive TP true positive rate TP rate unlabeled example unsupervised machine learning validation set weight wide model Bayes Theorem Bayesian Statistics Big Data Binary Variable Binomial Distribution Business Analytics Business Intelligence Categorical Variable Classification Clustering Confidence Interval Confusion Matrix Continuous Variable Data Mining Data Science Data Transformation Decision Tree Deep Learning Descriptive Statistics Dependent Variable Decile Degree of Freedom Dummy Variable EDA Evaluation Metrics` Feature reduction Feature Selection Frequentist Statistics fixed size infinite number of times F-Score Hierarchical Clustering Hypothesis Imputation Inferential Statistics IQR K-Means kNN Kurtosis Lasso Regression L1 regularization Linear Regression Y=aX+b y=0.2811x+13.9 Logistic Regression logistic regression Machine learning Mean Median Mode Multivariate analysis Naive Bayes Natural Language Processing Normal Distribution One Hot Encoding Ordinal Variable Outlier Precision and Recall Predictor Variable P-Value Q Quartile Range Regression Reinforcement Learning Response Variable Ridge Regression L2 regularization α = 0: α = ∞: 0 < α < ∞: ROC-AUC Semi-Supervised Learning Skewness Standard Deviation Standard error Statistics Supervised Learning SVM Support Vectors Type I error Type I error Type II error Type II error T-Test Univariate Analysis Unsupervised Learning Variance
